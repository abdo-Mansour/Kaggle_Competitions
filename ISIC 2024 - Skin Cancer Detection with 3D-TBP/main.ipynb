{"cells":[{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:55:40.143614Z","iopub.status.idle":"2024-07-17T09:55:53.617524Z","shell.execute_reply":"2024-07-17T09:55:53.616423Z","shell.execute_reply.started":"2024-07-17T09:55:40.144251Z"},"trusted":true},"outputs":[],"source":["# !pip install torchsummary"]},{"cell_type":"code","execution_count":72,"metadata":{"execution":{"iopub.execute_input":"2024-07-17T09:55:53.620758Z","iopub.status.busy":"2024-07-17T09:55:53.619932Z","iopub.status.idle":"2024-07-17T09:56:01.077690Z","shell.execute_reply":"2024-07-17T09:56:01.076908Z","shell.execute_reply.started":"2024-07-17T09:55:53.620719Z"},"trusted":true},"outputs":[],"source":["import torch\n","import os\n","import cv2\n","import pandas as pd\n","import numpy as np\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.torch_version\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","from torch.utils.data import DataLoader, Dataset\n","from torchsummary import summary\n","from torchvision import transforms\n","from torchmetrics import Accuracy, Precision, Recall\n","\n","import cv2\n","from joblib import Parallel, delayed\n","\n","from torch.cuda.amp import GradScaler, autocast\n"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2.3.1+cu121\n"]}],"source":["import torch\n","print(torch.__version__)"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2024-07-17T09:56:01.079403Z","iopub.status.busy":"2024-07-17T09:56:01.078869Z","iopub.status.idle":"2024-07-17T09:56:01.117478Z","shell.execute_reply":"2024-07-17T09:56:01.116482Z","shell.execute_reply.started":"2024-07-17T09:56:01.079368Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cuda device\n"]}],"source":["device = (\n","    \"cuda\"\n","    if torch.cuda.is_available()\n","    else \"mps\"\n","    if torch.backends.mps.is_available()\n","    else \"cpu\"\n",")\n","print(f\"Using {device} device\")"]},{"cell_type":"code","execution_count":75,"metadata":{"trusted":true},"outputs":[],"source":["iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n","main_path = '/kaggle/input/isic-2024-challenge' if iskaggle else 'data/isic-2024-challenge'"]},{"cell_type":"code","execution_count":149,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\abdfa\\AppData\\Local\\Temp\\ipykernel_18372\\3275392473.py:4: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n","  train_metadata_df = pd.read_csv(train_metadata_path)\n"]},{"name":"stdout","output_type":"stream","text":["401059\n"]}],"source":["train_metadata_path = '/kaggle/input/isic-2024-challenge/train-metadata.csv' if iskaggle else 'data/isic-2024-challenge/train-metadata.csv'\n","test_metadata_path = '/kaggle/input/isic-2024-challenge/test-metadata.csv' if iskaggle else 'data/isic-2024-challenge/test-metadata.csv'\n","\n","train_metadata_df = pd.read_csv(train_metadata_path)\n","test_metadata_df = pd.read_csv(test_metadata_path)\n","\n","print(len(train_metadata_df))"]},{"cell_type":"code","execution_count":154,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Positive samples: (393, 55)\n","Negative samples: (1965, 55)\n"]}],"source":["import sklearn.model_selection as train_test_split\n","\n","train_size = 0.8\n","# Splitting the train dataset into positive and negative samples and saving them in separate dataframes\n","postive_samples = train_metadata_df[train_metadata_df['target'] == 1]\n","negative_samples = train_metadata_df[train_metadata_df['target'] == 0]\n","\n","# TODO: Taking Sample of 1% of the data\n","# postive_samples = postive_samples.sample(frac=0.1)\n","negative_samples = negative_samples.sample(frac=5*postive_samples.shape[0]/negative_samples.shape[0])\n","\n","print(f\"Positive samples: {postive_samples.shape}\")\n","print(f\"Negative samples: {negative_samples.shape}\")"]},{"cell_type":"code","execution_count":155,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train positive samples: (314, 55)\n","Train negative samples: (1572, 55)\n","Val positive samples: (79, 55)\n","Val negative samples: (393, 55)\n"]}],"source":["\n","# Splitting each type of samples into train and validation sets\n","train_positive_samples, val_positive_samples = train_test_split.train_test_split(postive_samples,test_size=1-train_size)\n","train_negative_samples, val_negative_samples = train_test_split.train_test_split(negative_samples,test_size=1-train_size)\n","print(f\"Train positive samples: {train_positive_samples.shape}\")\n","print(f\"Train negative samples: {train_negative_samples.shape}\")\n","print(f\"Val positive samples: {val_positive_samples.shape}\")\n","print(f\"Val negative samples: {val_negative_samples.shape}\")\n"]},{"cell_type":"code","execution_count":156,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train samples: (1886, 55)\n","Val samples: (472, 55)\n","Test samples: (3, 44)\n"]}],"source":["\n","# Concatenating the positive and negative samples to get the train and validation sets\n","train_metadata_df = pd.concat([train_positive_samples, train_negative_samples])\n","val_metadata_df = pd.concat([val_positive_samples, val_negative_samples])\n","print(f\"Train samples: {train_metadata_df.shape}\")\n","print(f\"Val samples: {val_metadata_df.shape}\")\n","print(f\"Test samples: {test_metadata_df.shape}\")\n"]},{"cell_type":"code","execution_count":157,"metadata":{"trusted":true},"outputs":[],"source":["import h5pickle as h5py\n","from io import BytesIO\n","\n","train_hdf5_path = '/kaggle/input/isic-2024-challenge/train-image.hdf5' if iskaggle else 'data/isic-2024-challenge/train-image.hdf5'\n","test_hdf5_path = '/kaggle/input/isic-2024-challenge/test-image.hdf5' if iskaggle else 'data/isic-2024-challenge/test-image.hdf5'\n","train_image_path = '/kaggle/input/isic-2024-challenge/train-image/image' if iskaggle else 'data/isic-2024-challenge/train-image/image'"]},{"cell_type":"code","execution_count":158,"metadata":{"trusted":true},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, hdf5_file_path, metadata_df,target=None, transform=None):\n","        self.hdf5_file_path = hdf5_file_path\n","        self.hdf5_file = h5py.File(self.hdf5_file_path, 'r')\n","        self.metadata_df = metadata_df\n","        self.image_ids = metadata_df['isic_id']\n","        self.labels = target\n","        self.transform = transform\n","\n","        self.mean_of_color_channels = None  # Initialize as None\n","        self.std_of_color_channels = None   # Initialize as None\n","        # self._calculate_stats()\n","\n","    def __len__(self):\n","        return len(self.image_ids)\n","\n","    def __getitem__(self, idx):\n","        image_id = self.image_ids.iloc[idx]\n","        image = np.array(Image.open(BytesIO(np.array(self.hdf5_file[image_id]))),dtype=np.float32)/255\n","        \n","        if self.transform:\n","            image = self.transform(image=image)\n","            image = image['image']\n","\n","        if self.labels is not None:\n","            label = self.labels.iloc[idx]\n","            return image, label\n","        else:\n","            return image\n","\n","   "]},{"cell_type":"code","execution_count":166,"metadata":{"trusted":true},"outputs":[],"source":["# HyperParameters\n","dim = 224 \n","batch_size = 64"]},{"cell_type":"code","execution_count":167,"metadata":{"trusted":true},"outputs":[],"source":["train_transform = A.Compose([\n","    A.Resize(height=dim, width=dim), #resize \n","    A.OneOf([A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15),\n","             A.RandomBrightnessContrast() \n","             ], p=0.5),\n","    A.HorizontalFlip(p=0.5),\n","    A.VerticalFlip(p=0.5),\n","    # !!One needs to change the mean and std values to appropriate ones for this dataset.!!\n","    A.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=1.0),\n","    ToTensorV2(),\n","])\n","\n","\n","test_transform = A.Compose([\n","    A.Resize(height=dim, width=dim), #resize \n","    # !!One needs to change the mean and std values to appropriate ones for this dataset.!!\n","    A.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=1.0),\n","    ToTensorV2(),\n","])"]},{"cell_type":"code","execution_count":168,"metadata":{"trusted":true},"outputs":[],"source":["train_dataset = CustomDataset(train_hdf5_path,train_metadata_df,target=train_metadata_df['target'],transform=train_transform)\n","# train_image_dataset = CustomDatasetImage(train_image_path,train_metadata_df,target=train_metadata_df['target'],transform=train_transform)\n","val_dataset = CustomDataset(train_hdf5_path,val_metadata_df,target=val_metadata_df['target'],transform=train_transform)\n","test_dataset = CustomDataset(test_hdf5_path,test_metadata_df,transform=test_transform)"]},{"cell_type":"code","execution_count":169,"metadata":{"trusted":true},"outputs":[],"source":["n_w = 0\n","if iskaggle:\n","    n_w = 4\n","train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True,num_workers=n_w)\n","val_loader = DataLoader(val_dataset,batch_size=batch_size,shuffle=True,num_workers=n_w)\n","test_loader = DataLoader(test_dataset,batch_size=batch_size,shuffle=False,num_workers=n_w)"]},{"cell_type":"code","execution_count":170,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.metrics import roc_curve, auc\n","\n","def calculate_partial_auc_by_tpr(y_true, y_scores, max_tpr=0.8):\n","    # Calculate the ROC curve\n","    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n","    \n","    # Limit the TPR to the specified minimum TPR\n","    mask = tpr >= max_tpr\n","    fpr, tpr = fpr[mask], tpr[mask]\n","    \n","    # Calculate the partial AUC\n","    partial_auc = auc(fpr, tpr)\n","    \n","    # Normalize the partial AUC to the range [0, 1]\n","    partial_auc /= max_tpr\n","    \n","    return partial_auc"]},{"cell_type":"code","execution_count":175,"metadata":{"trusted":true},"outputs":[],"source":["class Model(nn.Module):\n","    def __init__(self,num_classes,device,dim = 32,num_epochs = 20,learning_rate = 0.001,early_stopping = False):\n","        super().__init__()\n","        self.num_of_classes = num_classes\n","        self.device = device\n","        self.dim = dim\n","        # Debugging\n","        self.DEBUG = True\n","        # Hyperparameters\n","        self.num_epochs = num_epochs\n","        self.learning_rate = learning_rate\n","        self.early_stopping = early_stopping\n","        # History while Training\n","        self.model_loss_history = []\n","\n","        self.model_train_acc_history = []\n","        self.model_train_pauc_history = []\n","        \n","        self.model_val_acc_history = []\n","        self.model_val_precision_history = []\n","        self.model_val_recall_history = []\n","        self.model_val_pauc_history = []\n","        \n","        self.model_lr_history = []\n","\n","        # Model Attributes\n","        self.criterion = nn.BCEWithLogitsLoss()\n","        self.optimizer = None\n","        self.accuracy = Accuracy(task= 'binary', average='macro').to(self.device)\n","        self.precision = Precision(task= 'binary', average='macro').to(self.device)\n","        self.recall = Recall(task= 'binary', average='macro').to(self.device)\n","        # Feature Extraction\n","        self.feature_extract = nn.Sequential(\n","            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=7, padding=1),\n","            nn.MaxPool2d(kernel_size=2),\n","            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=1),\n","            nn.MaxPool2d(kernel_size=2),\n","            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, padding=1),\n","            nn.MaxPool2d(kernel_size=2),\n","            nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, padding=1),\n","            nn.MaxPool2d(kernel_size=2),\n","            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, padding=1),\n","            nn.MaxPool2d(kernel_size=2),\n","            nn.Flatten()\n","        )\n","        \n","        # Classifier\n","        self.classifier = nn.Sequential(\n","            nn.Linear(1152 , 200),  # Adjust the size based on the input image size\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(200, 100),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(100, 1)\n","\n","        )\n","        \n","    def forward(self, x):\n","        x = self.feature_extract(x)\n","        x = self.classifier(x)\n","        return x\n","    \n","    def predict(self, img):\n","        '''\n","        returns the predicted classes for the given images\n","        '''\n","        self.eval()\n","        with torch.no_grad():\n","            img = img.to(self.device)\n","            output = self(img)\n","            prob_outputs = torch.sigmoid(output)\n","            return prob_outputs\n","            \n","        \n","\n","    \n","    def eval_val(self, data_loader):\n","        '''\n","        returns the accuracy, precision, recall , partial AUC, predicted probabilities and actual labels for the given data loader\n","        '''\n","        self.eval()\n","        y_prob_pred = []\n","        y_actual = []\n","        with torch.no_grad():\n","            for images, actuals in data_loader:\n","                \n","                images, actuals = images.to(self.device), actuals.to(self.device)\n","                # Get the model predictions\n","                output = self(images)\n","                # Get the probability outputs\n","                prob_outputs = torch.sigmoid(output)\n","                # Get the binary predictions\n","                batch_pred = (prob_outputs > 0.5).float()\n","                # Reshape the actuals\n","                actuals = actuals.unsqueeze(1).float()\n","\n","                y_prob_pred.extend(prob_outputs.cpu().numpy())\n","                y_actual.extend(actuals.cpu().numpy())\n","\n","                # Update the metrics\n","                self.accuracy(batch_pred, actuals)\n","                self.precision(batch_pred, actuals)\n","                self.recall(batch_pred, actuals)\n","        \n","        # Calculate the partial AUC\n","        partial_auc = calculate_partial_auc_by_tpr(y_true=y_actual, y_scores=y_prob_pred, max_tpr=0.8)\n","\n","\n","        return self.accuracy.compute(), self.precision.compute(), self.recall.compute(), partial_auc, y_prob_pred, y_actual\n","    \n","    def train_model(self, train_loader, val_loader):\n","        \n","        last_accuracy = -100\n","        self.optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n","        scaler = GradScaler()\n","\n","        for epoch in range(self.num_epochs):\n","            self.train()\n","            running_loss = 0.0\n","\n","            for i, (images, labels) in enumerate(train_loader):\n","                \n","                images, labels = images.to(self.device), labels.to(self.device)\n","                self.optimizer.zero_grad()\n","                with autocast():\n","                    outputs = self(images)\n","                    labels = labels.unsqueeze(1).float()\n","                    loss = self.criterion(outputs, labels)\n","                scaler.scale(loss).backward()\n","                scaler.step(self.optimizer)\n","                scaler.update()\n","\n","                running_loss += loss.item()\n","                if i%1000 == 0 and self.DEBUG:\n","                    print(\" Step [{}/{}] Loss: {}\".format(i, len(train_loader), loss.item()))\n","                    \n","            val_acc, val_precision, val_recall, val_pauc, _ , _ = self.eval_val(val_loader)\n","            train_acc, _, _, train_pauc, _, _ = self.eval_val(train_loader)\n","\n","            self.model_loss_history.append(running_loss/len(train_loader))\n","            self.model_train_acc_history.append(train_acc.item())\n","            self.model_train_pauc_history.append(train_pauc)\n","            self.model_val_acc_history.append(val_acc.item())\n","            self.model_val_precision_history.append(val_precision.item())\n","            self.model_val_recall_history.append(val_recall.item())\n","            self.model_val_pauc_history.append(val_pauc)\n","            self.model_lr_history.append(self.optimizer.param_groups[0]['lr'])\n","            \n","            print(f'Epoch: {epoch+1}/{self.num_epochs}, Loss: {loss.item()},Train Acc: {train_acc}, Val Acc: {val_acc}, Val Precision: {val_precision}, Val Recall: {val_recall},Train PAUC: {train_pauc}, Val PAUC: {val_pauc}')\n","            \n","            if val_acc > last_accuracy:\n","                last_accuracy = val_acc\n","            elif self.early_stopping:\n","                break\n","        \n","        print('Finished Training')\n","\n","    def plot_history(self):\n","        # making two plots one for loss and other for accuracy\n","        fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n","        fig.suptitle('Model Training History')\n","        axs[0, 0].plot(self.model_loss_history)\n","        axs[0, 0].set_title('Model Loss')\n","        axs[0, 0].set_xlabel('Epochs')\n","        axs[0, 0].set_ylabel('Loss')\n","\n","        axs[0, 1].plot(self.model_train_acc_history, label='Train')\n","        axs[0, 1].plot(self.model_val_acc_history, label='Val')\n","        axs[0, 1].set_title('Model Accuracy')\n","        axs[0, 1].set_xlabel('Epochs')\n","        axs[0, 1].set_ylabel('Accuracy')\n","        axs[0, 1].legend()\n","\n","        axs[1, 0].plot(self.model_val_precision_history)\n","        axs[1, 0].set_title('Model Precision')\n","        axs[1, 0].set_xlabel('Epochs')\n","        axs[1, 0].set_ylabel('Precision')\n","        \n","        axs[1, 1].plot(self.model_val_recall_history)\n","        axs[1, 1].set_title('Model Recall')\n","        axs[1, 1].set_xlabel('Epochs')\n","        axs[1, 1].set_ylabel('Recall')\n","\n","        axs[0, 2].plot(self.model_lr_history)\n","        axs[0, 2].set_title('Learning Rate')\n","        axs[0, 2].set_xlabel('Epochs')\n","        axs[0, 2].set_ylabel('Learning Rate')\n","        \n","        axs[1, 2].plot(self.model_val_pauc_history)\n","        axs[1, 2].set_title('Model Partial AUC')\n","        axs[1, 2].set_xlabel('Epochs')\n","        axs[1, 2].set_ylabel('Partial AUC')\n","        \n","\n","        plt.show()\n","    \n","    def save_model(self):\n","        torch.save(self.state_dict(),type(self).__name__+'.pth')\n","\n","    def print_summary(self):\n","        summary(self, (3, self.dim, self.dim))"]},{"cell_type":"code","execution_count":177,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 32, 220, 220]           4,736\n","         MaxPool2d-2         [-1, 32, 110, 110]               0\n","            Conv2d-3         [-1, 64, 108, 108]          51,264\n","         MaxPool2d-4           [-1, 64, 54, 54]               0\n","            Conv2d-5          [-1, 128, 52, 52]         204,928\n","         MaxPool2d-6          [-1, 128, 26, 26]               0\n","            Conv2d-7           [-1, 64, 26, 26]          73,792\n","         MaxPool2d-8           [-1, 64, 13, 13]               0\n","            Conv2d-9           [-1, 32, 13, 13]          18,464\n","        MaxPool2d-10             [-1, 32, 6, 6]               0\n","          Flatten-11                 [-1, 1152]               0\n","           Linear-12                  [-1, 200]         230,600\n","             ReLU-13                  [-1, 200]               0\n","          Dropout-14                  [-1, 200]               0\n","           Linear-15                  [-1, 100]          20,100\n","             ReLU-16                  [-1, 100]               0\n","          Dropout-17                  [-1, 100]               0\n","           Linear-18                    [-1, 1]             101\n","================================================================\n","Total params: 603,985\n","Trainable params: 603,985\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 25.67\n","Params size (MB): 2.30\n","Estimated Total Size (MB): 28.55\n","----------------------------------------------------------------\n"]}],"source":["num_of_classes = 2\n","cnn = Model(num_classes=num_of_classes, \n","            device=device, \n","            dim=dim, \n","            num_epochs=10, \n","            learning_rate=0.001,\n","            early_stopping=False)\n","cnn.to(device)\n","cnn.print_summary()"]},{"cell_type":"code","execution_count":178,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[" Step [0/30] Loss: 0.6881775856018066\n","Epoch: 1/10, Loss: 0.2757985293865204,Train Acc: 0.8333333134651184, Val Acc: 0.8326271176338196, Val Precision: 0.0, Val Recall: 0.0,Train PAUC: 0.29389591538224663, Val PAUC: 0.21457387187167845\n"," Step [0/30] Loss: 0.39764153957366943\n","Epoch: 2/10, Loss: 0.3761991560459137,Train Acc: 0.8333333134651184, Val Acc: 0.8332155346870422, Val Precision: 0.0, Val Recall: 0.0,Train PAUC: 0.20232907489343777, Val PAUC: 0.1823243791670693\n"," Step [0/30] Loss: 0.44641023874282837\n","Epoch: 3/10, Loss: 0.5528662800788879,Train Acc: 0.8333333134651184, Val Acc: 0.8332690596580505, Val Precision: 0.0, Val Recall: 0.0,Train PAUC: 0.3303329767750929, Val PAUC: 0.21405047186523657\n"," Step [0/30] Loss: 0.4929148554801941\n","Epoch: 4/10, Loss: 0.579434871673584,Train Acc: 0.8333333134651184, Val Acc: 0.8332891464233398, Val Precision: 0.0, Val Recall: 0.0,Train PAUC: 0.28329919693359906, Val PAUC: 0.3359020195187941\n"," Step [0/30] Loss: 0.35139915347099304\n","Epoch: 5/10, Loss: 0.4507209360599518,Train Acc: 0.8333333134651184, Val Acc: 0.8332996964454651, Val Precision: 0.0, Val Recall: 0.0,Train PAUC: 0.3308787033435438, Val PAUC: 0.4427964054498019\n"," Step [0/30] Loss: 0.5171289443969727\n","Epoch: 6/10, Loss: 0.4880323112010956,Train Acc: 0.8333333134651184, Val Acc: 0.8333061337471008, Val Precision: 0.0, Val Recall: 0.0,Train PAUC: 0.3538726580606473, Val PAUC: 0.4050512126775533\n"," Step [0/30] Loss: 0.5056665539741516\n","Epoch: 7/10, Loss: 0.552259624004364,Train Acc: 0.8333333134651184, Val Acc: 0.8333105444908142, Val Precision: 0.0, Val Recall: 0.0,Train PAUC: 0.18066081789598226, Val PAUC: 0.17662737140464457\n"," Step [0/30] Loss: 0.5435519218444824\n","Epoch: 8/10, Loss: 0.34809601306915283,Train Acc: 0.8333333134651184, Val Acc: 0.8333137035369873, Val Precision: 0.0, Val Recall: 0.0,Train PAUC: 0.28370944150013777, Val PAUC: 0.1864310561406899\n"," Step [0/30] Loss: 0.46544724702835083\n","Epoch: 9/10, Loss: 0.3741515874862671,Train Acc: 0.8333333134651184, Val Acc: 0.8333160877227783, Val Precision: 0.0, Val Recall: 0.0,Train PAUC: 0.21934156253545314, Val PAUC: 0.22568605662382835\n"," Step [0/30] Loss: 0.41595208644866943\n","Epoch: 10/10, Loss: 0.607342541217804,Train Acc: 0.8333333134651184, Val Acc: 0.8333179950714111, Val Precision: 0.0, Val Recall: 0.0,Train PAUC: 0.17576447302312767, Val PAUC: 0.2791735111282893\n","Finished Training\n"]}],"source":["cnn.train_model(train_loader=train_loader,val_loader=val_loader)"]},{"cell_type":"code","execution_count":179,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.19436257931523176, Precision: 0.0, Recall: 0.0\n"]}],"source":["cnn_acc , cnn_precision, cnn_recall , cnn_pauc, y_pred, y_actual = cnn.eval_val(val_loader)\n","print(f\"Accuracy: {cnn_pauc}, Precision: {cnn_precision}, Recall: {cnn_recall}\")"]},{"cell_type":"code","execution_count":180,"metadata":{},"outputs":[{"data":{"text/plain":["(472, 0)"]},"execution_count":180,"metadata":{},"output_type":"execute_result"}],"source":["# 0.5 threshold\n","y_pred = np.array(y_pred)\n","y_actual = np.array(y_actual).astype(int)\n","y_pred = (y_pred > 0.5).astype(int)\n","\n","# output the incorrect predictions\n","incorrect_predictions = np.where(y_pred != y_actual)[0]\n","number_zero = np.sum(y_pred == 0)\n","number_one = np.sum(y_pred == 1)\n","number_zero, number_one"]},{"cell_type":"code","execution_count":181,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Partial AUC: 0.19436257931523176\n"]}],"source":["print(f\"Partial AUC: {cnn_pauc}\")\n"]},{"cell_type":"code","execution_count":182,"metadata":{},"outputs":[],"source":["cnn.save_model()"]},{"cell_type":"code","execution_count":183,"metadata":{},"outputs":[{"data":{"text/plain":["array([0.18550608, 0.2090997 , 0.1830071 ], dtype=float32)"]},"execution_count":183,"metadata":{},"output_type":"execute_result"}],"source":["y_prod_pred = []\n","for images in test_loader:\n","    images = images.to(device)\n","    prob_outputs = cnn.predict(images)\n","    y_prod_pred.extend(prob_outputs.cpu().numpy())\n","\n","y_prod_pred = np.array(y_prod_pred)\n","y_prod_pred = y_prod_pred.flatten()\n","y_prod_pred"]},{"cell_type":"code","execution_count":184,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>isic_id</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ISIC_0015657</td>\n","      <td>0.185506</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ISIC_0015729</td>\n","      <td>0.209100</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ISIC_0015740</td>\n","      <td>0.183007</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        isic_id    target\n","0  ISIC_0015657  0.185506\n","1  ISIC_0015729  0.209100\n","2  ISIC_0015740  0.183007"]},"execution_count":184,"metadata":{},"output_type":"execute_result"}],"source":["submission_df = pd.DataFrame({'isic_id': test_metadata_df['isic_id'], 'target': y_prod_pred})\n","submission_df "]},{"cell_type":"code","execution_count":185,"metadata":{},"outputs":[],"source":["submission_df.to_csv('submission.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":9094797,"sourceId":63056,"sourceType":"competition"}],"dockerImageVersionId":30732,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":4}
