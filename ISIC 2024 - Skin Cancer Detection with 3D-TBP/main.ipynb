{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95951e99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T05:49:20.422129Z",
     "iopub.status.busy": "2024-08-05T05:49:20.421541Z",
     "iopub.status.idle": "2024-08-05T05:49:20.425999Z",
     "shell.execute_reply": "2024-08-05T05:49:20.425278Z"
    },
    "papermill": {
     "duration": 0.01564,
     "end_time": "2024-08-05T05:49:20.427906",
     "exception": false,
     "start_time": "2024-08-05T05:49:20.412266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "419b79ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T05:49:20.443784Z",
     "iopub.status.busy": "2024-08-05T05:49:20.443551Z",
     "iopub.status.idle": "2024-08-05T05:49:31.185042Z",
     "shell.execute_reply": "2024-08-05T05:49:31.184090Z"
    },
    "papermill": {
     "duration": 10.752278,
     "end_time": "2024-08-05T05:49:31.187617",
     "exception": false,
     "start_time": "2024-08-05T05:49:20.435339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.torch_version\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "# from torchsummary import summary\n",
    "from torchvision import transforms\n",
    "from torchmetrics import Accuracy, Precision, Recall\n",
    "import timm\n",
    "import cv2\n",
    "\n",
    "from torch.cuda.amp import GradScaler, autocast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76f15b79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T05:49:31.204064Z",
     "iopub.status.busy": "2024-08-05T05:49:31.203730Z",
     "iopub.status.idle": "2024-08-05T05:49:31.208625Z",
     "shell.execute_reply": "2024-08-05T05:49:31.207692Z"
    },
    "papermill": {
     "duration": 0.01549,
     "end_time": "2024-08-05T05:49:31.210792",
     "exception": false,
     "start_time": "2024-08-05T05:49:31.195302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5e5ade0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T05:49:31.226770Z",
     "iopub.status.busy": "2024-08-05T05:49:31.226520Z",
     "iopub.status.idle": "2024-08-05T05:49:31.293707Z",
     "shell.execute_reply": "2024-08-05T05:49:31.292697Z"
    },
    "papermill": {
     "duration": 0.077762,
     "end_time": "2024-08-05T05:49:31.295916",
     "exception": false,
     "start_time": "2024-08-05T05:49:31.218154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff1e0fe1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T05:49:31.312364Z",
     "iopub.status.busy": "2024-08-05T05:49:31.312021Z",
     "iopub.status.idle": "2024-08-05T05:49:31.316837Z",
     "shell.execute_reply": "2024-08-05T05:49:31.315756Z"
    },
    "papermill": {
     "duration": 0.015211,
     "end_time": "2024-08-05T05:49:31.318754",
     "exception": false,
     "start_time": "2024-08-05T05:49:31.303543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n",
    "main_path = '/kaggle/input/isic-2024-challenge' if iskaggle else 'data/isic-2024-challenge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e92f25a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T05:49:31.335393Z",
     "iopub.status.busy": "2024-08-05T05:49:31.335056Z",
     "iopub.status.idle": "2024-08-05T05:49:38.230264Z",
     "shell.execute_reply": "2024-08-05T05:49:38.229185Z"
    },
    "papermill": {
     "duration": 6.905768,
     "end_time": "2024-08-05T05:49:38.232379",
     "exception": false,
     "start_time": "2024-08-05T05:49:31.326611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/3275392473.py:4: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_metadata_df = pd.read_csv(train_metadata_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401059\n"
     ]
    }
   ],
   "source": [
    "train_metadata_path = '/kaggle/input/isic-2024-challenge/train-metadata.csv' if iskaggle else 'data/isic-2024-challenge/train-metadata.csv'\n",
    "test_metadata_path = '/kaggle/input/isic-2024-challenge/test-metadata.csv' if iskaggle else 'data/isic-2024-challenge/test-metadata.csv'\n",
    "\n",
    "train_metadata_df = pd.read_csv(train_metadata_path)\n",
    "test_metadata_df = pd.read_csv(test_metadata_path)\n",
    "\n",
    "print(len(train_metadata_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a0f5174",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T05:49:38.249185Z",
     "iopub.status.busy": "2024-08-05T05:49:38.248905Z",
     "iopub.status.idle": "2024-08-05T05:49:38.473556Z",
     "shell.execute_reply": "2024-08-05T05:49:38.472483Z"
    },
    "papermill": {
     "duration": 0.235279,
     "end_time": "2024-08-05T05:49:38.475719",
     "exception": false,
     "start_time": "2024-08-05T05:49:38.240440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: (393, 55)\n",
      "Negative samples: (39300, 55)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.model_selection as train_test_split\n",
    "\n",
    "train_size = 0.8\n",
    "# Splitting the train dataset into positive and negative samples and saving them in separate dataframes\n",
    "postive_samples = train_metadata_df[train_metadata_df['target'] == 1]\n",
    "negative_samples = train_metadata_df[train_metadata_df['target'] == 0]\n",
    "\n",
    "# postive_samples = postive_samples.sample(frac=0.1)\n",
    "negative_samples = negative_samples.sample(frac=100*(postive_samples.shape[0]/negative_samples.shape[0]))\n",
    "\n",
    "print(f\"Positive samples: {postive_samples.shape}\")\n",
    "print(f\"Negative samples: {negative_samples.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01afa254",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T05:49:38.493487Z",
     "iopub.status.busy": "2024-08-05T05:49:38.493179Z",
     "iopub.status.idle": "2024-08-05T05:49:38.529850Z",
     "shell.execute_reply": "2024-08-05T05:49:38.528871Z"
    },
    "papermill": {
     "duration": 0.048096,
     "end_time": "2024-08-05T05:49:38.531730",
     "exception": false,
     "start_time": "2024-08-05T05:49:38.483634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train positive samples: (314, 55)\n",
      "Train negative samples: (31440, 55)\n",
      "Val positive samples: (79, 55)\n",
      "Val negative samples: (7860, 55)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Splitting each type of samples into train and validation sets\n",
    "train_positive_samples, val_positive_samples = train_test_split.train_test_split(postive_samples,test_size=1-train_size)\n",
    "train_negative_samples, val_negative_samples = train_test_split.train_test_split(negative_samples,test_size=1-train_size)\n",
    "print(f\"Train positive samples: {train_positive_samples.shape}\")\n",
    "print(f\"Train negative samples: {train_negative_samples.shape}\")\n",
    "print(f\"Val positive samples: {val_positive_samples.shape}\")\n",
    "print(f\"Val negative samples: {val_negative_samples.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e332bef9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T05:49:38.548540Z",
     "iopub.status.busy": "2024-08-05T05:49:38.548252Z",
     "iopub.status.idle": "2024-08-05T05:49:38.604976Z",
     "shell.execute_reply": "2024-08-05T05:49:38.603858Z"
    },
    "papermill": {
     "duration": 0.067366,
     "end_time": "2024-08-05T05:49:38.606968",
     "exception": false,
     "start_time": "2024-08-05T05:49:38.539602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: (31754, 55)\n",
      "Val samples: (7939, 55)\n",
      "Test samples: (3, 44)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Concatenating the positive and negative samples to get the train and validation sets\n",
    "train_metadata_df = pd.concat([train_positive_samples, train_negative_samples])\n",
    "val_metadata_df = pd.concat([val_positive_samples, val_negative_samples])\n",
    "print(f\"Train samples: {train_metadata_df.shape}\")\n",
    "print(f\"Val samples: {val_metadata_df.shape}\")\n",
    "print(f\"Test samples: {test_metadata_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dff7d89f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T05:49:38.624311Z",
     "iopub.status.busy": "2024-08-05T05:49:38.623634Z",
     "iopub.status.idle": "2024-08-05T05:49:38.764495Z",
     "shell.execute_reply": "2024-08-05T05:49:38.763747Z"
    },
    "papermill": {
     "duration": 0.151508,
     "end_time": "2024-08-05T05:49:38.766429",
     "exception": false,
     "start_time": "2024-08-05T05:49:38.614921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "from io import BytesIO\n",
    "\n",
    "train_hdf5_path = '/kaggle/input/isic-2024-challenge/train-image.hdf5' if iskaggle else 'data/isic-2024-challenge/train-image.hdf5'\n",
    "test_hdf5_path = '/kaggle/input/isic-2024-challenge/test-image.hdf5' if iskaggle else 'data/isic-2024-challenge/test-image.hdf5'\n",
    "train_image_path = '/kaggle/input/isic-2024-challenge/train-image/image' if iskaggle else 'data/isic-2024-challenge/train-image/image'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8196746b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T05:49:38.783592Z",
     "iopub.status.busy": "2024-08-05T05:49:38.783294Z",
     "iopub.status.idle": "2024-08-05T05:49:38.791231Z",
     "shell.execute_reply": "2024-08-05T05:49:38.790576Z"
    },
    "papermill": {
     "duration": 0.018435,
     "end_time": "2024-08-05T05:49:38.792978",
     "exception": false,
     "start_time": "2024-08-05T05:49:38.774543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, hdf5_file_path, metadata_df,target=None, transform=None):\n",
    "        self.hdf5_file_path = hdf5_file_path\n",
    "        self.hdf5_file = h5py.File(self.hdf5_file_path, 'r')\n",
    "        self.metadata_df = metadata_df\n",
    "        self.image_ids = metadata_df['isic_id']\n",
    "        self.labels = target\n",
    "        self.transform = transform\n",
    "\n",
    "        self.mean_of_color_channels = None  # Initialize as None\n",
    "        self.std_of_color_channels = None   # Initialize as None\n",
    "        # self._calculate_stats()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids.iloc[idx]\n",
    "        image = np.array(Image.open(BytesIO(np.array(self.hdf5_file[image_id]))),dtype=np.float32)/255\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)\n",
    "            image = image['image']\n",
    "\n",
    "        if self.labels is not None:\n",
    "            label = self.labels.iloc[idx]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbd06fc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T05:49:38.809844Z",
     "iopub.status.busy": "2024-08-05T05:49:38.809373Z",
     "iopub.status.idle": "2024-08-05T05:49:38.813075Z",
     "shell.execute_reply": "2024-08-05T05:49:38.812301Z"
    },
    "papermill": {
     "duration": 0.01417,
     "end_time": "2024-08-05T05:49:38.814942",
     "exception": false,
     "start_time": "2024-08-05T05:49:38.800772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "dim = 384 \n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13c5ff26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T05:49:38.832788Z",
     "iopub.status.busy": "2024-08-05T05:49:38.832549Z",
     "iopub.status.idle": "2024-08-05T05:49:38.840652Z",
     "shell.execute_reply": "2024-08-05T05:49:38.839776Z"
    },
    "papermill": {
     "duration": 0.019861,
     "end_time": "2024-08-05T05:49:38.842622",
     "exception": false,
     "start_time": "2024-08-05T05:49:38.822761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.Resize(height=dim, width=dim), #resize \n",
    "    \n",
    "    A.OneOf([\n",
    "        A.Transpose(p=1.0),\n",
    "        A.VerticalFlip(p=1.0),\n",
    "        A.HorizontalFlip(p=1.0)\n",
    "    ], p=0.5),  # Transpose, vertical flip, or horizontal flip with equal probability   \n",
    "\n",
    "    A.GaussNoise(var_limit=(5.0, 30.0), p=1.0),  # Gaussian noise  \n",
    "    A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=1.0),  # Hue, saturation, and value adjustment\n",
    "    A.CoarseDropout(p=1.0),  # Cutout augmentation\n",
    "    # !!One needs to change the mean and std values to appropriate ones for this dataset.!!\n",
    "    A.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=1.0),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(height=dim, width=dim), #resize \n",
    "    # !!One needs to change the mean and std values to appropriate ones for this dataset.!!\n",
    "    A.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=1.0),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24bbc6c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T05:49:38.859984Z",
     "iopub.status.busy": "2024-08-05T05:49:38.859248Z",
     "iopub.status.idle": "2024-08-05T05:49:38.874195Z",
     "shell.execute_reply": "2024-08-05T05:49:38.873516Z"
    },
    "papermill": {
     "duration": 0.025437,
     "end_time": "2024-08-05T05:49:38.876135",
     "exception": false,
     "start_time": "2024-08-05T05:49:38.850698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_hdf5_path,train_metadata_df,target=train_metadata_df['target'],transform=train_transform)\n",
    "# train_image_dataset = CustomDatasetImage(train_image_path,train_metadata_df,target=train_metadata_df['target'],transform=train_transform)\n",
    "val_dataset = CustomDataset(train_hdf5_path,val_metadata_df,target=val_metadata_df['target'],transform=train_transform)\n",
    "test_dataset = CustomDataset(test_hdf5_path,test_metadata_df,transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "773fc627",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T05:49:38.893002Z",
     "iopub.status.busy": "2024-08-05T05:49:38.892747Z",
     "iopub.status.idle": "2024-08-05T05:49:38.897868Z",
     "shell.execute_reply": "2024-08-05T05:49:38.897056Z"
    },
    "papermill": {
     "duration": 0.01564,
     "end_time": "2024-08-05T05:49:38.899731",
     "exception": false,
     "start_time": "2024-08-05T05:49:38.884091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_w = 0\n",
    "if iskaggle:\n",
    "    n_w = 4\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True,num_workers=n_w)\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_size,shuffle=True,num_workers=n_w)\n",
    "test_loader = DataLoader(test_dataset,batch_size=batch_size,shuffle=False,num_workers=n_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bbe83b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T05:49:38.916224Z",
     "iopub.status.busy": "2024-08-05T05:49:38.915970Z",
     "iopub.status.idle": "2024-08-05T05:49:38.921249Z",
     "shell.execute_reply": "2024-08-05T05:49:38.920459Z"
    },
    "papermill": {
     "duration": 0.015585,
     "end_time": "2024-08-05T05:49:38.923114",
     "exception": false,
     "start_time": "2024-08-05T05:49:38.907529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "def calculate_partial_auc_by_tpr(y_true, y_scores, min_tpr=0.8):\n",
    "    v_gt = abs(y_true-1)\n",
    "    v_pred = 1 - y_scores\n",
    "    max_fpr = abs(1-min_tpr)\n",
    "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
    "    # change scale from [0.5, 1.0] to [0.5 * max_fpr**2, max_fpr]\n",
    "    # https://math.stackexchange.com/questions/914823/shift-numbers-into-a-different-range\n",
    "    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
    "    \n",
    "    return partial_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19b7da62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T05:49:38.940260Z",
     "iopub.status.busy": "2024-08-05T05:49:38.940007Z",
     "iopub.status.idle": "2024-08-05T05:49:38.975483Z",
     "shell.execute_reply": "2024-08-05T05:49:38.974759Z"
    },
    "papermill": {
     "duration": 0.046432,
     "end_time": "2024-08-05T05:49:38.977398",
     "exception": false,
     "start_time": "2024-08-05T05:49:38.930966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,num_classes,device,dim = 32,num_epochs = 20,learning_rate = 0.001,early_stopping = False):\n",
    "        super().__init__()\n",
    "        self.num_of_classes = num_classes\n",
    "        self.device = device\n",
    "        self.dim = dim\n",
    "        # Debugging\n",
    "        self.DEBUG = True\n",
    "        # Hyperparameters\n",
    "        self.num_epochs = num_epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.early_stopping = early_stopping\n",
    "        # History while Training\n",
    "        self.model_loss_history = []\n",
    "\n",
    "        self.model_train_acc_history = []\n",
    "        self.model_train_pauc_history = []\n",
    "        \n",
    "        self.model_val_acc_history = []\n",
    "        self.model_val_precision_history = []\n",
    "        self.model_val_recall_history = []\n",
    "        self.model_val_pauc_history = []\n",
    "        \n",
    "        self.model_lr_history = []\n",
    "\n",
    "        # Model Attributes\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        self.optimizer = None\n",
    "        self.accuracy = Accuracy(task= 'binary', average='macro').to(self.device)\n",
    "        self.precision = Precision(task= 'binary', average='macro').to(self.device)\n",
    "        self.recall = Recall(task= 'binary', average='macro').to(self.device)\n",
    "        \n",
    "        # Load ResNet-18 from timm\n",
    "#         self.feature_extractor = timm.create_model('resnet18', pretrained=True, num_classes=0)\n",
    "        self.feature_extractor = models.resnet18(pretrained=False)\n",
    "        self.feature_extractor.load_state_dict(torch.load(\"/kaggle/input/resnet18/resnet18.pth\"))\n",
    "        self.feature_extractor.to(self.device)\n",
    "        \n",
    "\n",
    "        # Add custom classifier head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1000, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256,50),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(50,1)\n",
    "        ).to(self.device)\n",
    "        \n",
    "\n",
    "    def freeze_backbone(self, freeze=True):\n",
    "        # Freeze/unfreeze feature extractor layers\n",
    "        for param in self.feature_extractor.parameters():\n",
    "            param.requires_grad = not freeze\n",
    "            \n",
    "    def freeze_classifier(self, freeze=True):\n",
    "        for param in self.classifier.parameters():\n",
    "            param.requires_grad = not freeze\n",
    "    def forward(self, x):\n",
    "        # Feature extraction using ResNet-18\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    def predict(self, img):\n",
    "        '''\n",
    "        returns the predicted classes for the given images\n",
    "        '''\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            img = img.to(self.device)\n",
    "            output = self(img)\n",
    "            prob_outputs = torch.sigmoid(output)\n",
    "            return prob_outputs\n",
    "            \n",
    "        \n",
    "\n",
    "    \n",
    "    def eval_val(self, data_loader):\n",
    "        '''\n",
    "        returns the accuracy, precision, recall , partial AUC, predicted probabilities and actual labels for the given data loader\n",
    "        '''\n",
    "        self.eval()\n",
    "        y_prob_pred = np.array([])\n",
    "        y_actual = np.array([])\n",
    "        with torch.no_grad():\n",
    "            for images, actuals in data_loader:\n",
    "                \n",
    "                images, actuals = images.to(self.device), actuals.to(self.device)\n",
    "                # Get the model predictions\n",
    "                output = self(images)\n",
    "                # Get the probability outputs\n",
    "                prob_outputs = torch.sigmoid(output)\n",
    "                # Get the binary predictions\n",
    "                batch_pred = (prob_outputs > 0.5).float()\n",
    "                # Reshape the actuals\n",
    "                actuals = actuals.unsqueeze(1).float()\n",
    "                \n",
    "                y_prob_pred = np.concatenate((y_prob_pred, prob_outputs.cpu().numpy().squeeze()))\n",
    "                y_actual = np.concatenate((y_actual, actuals.cpu().numpy().squeeze()))\n",
    "\n",
    "                # Update the metrics\n",
    "                self.accuracy(batch_pred, actuals)\n",
    "                self.precision(batch_pred, actuals)\n",
    "                self.recall(batch_pred, actuals)\n",
    "        \n",
    "        # Calculate the partial AUC\n",
    "        partial_auc = calculate_partial_auc_by_tpr(y_true=y_actual, y_scores=y_prob_pred, min_tpr=0.8)\n",
    "\n",
    "        return self.accuracy.compute(), self.precision.compute(), self.recall.compute(), partial_auc, y_prob_pred, y_actual\n",
    "    \n",
    "    def train_model(self, train_loader, val_loader):\n",
    "        \n",
    "        last_accuracy = -100\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        scaler = GradScaler()\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.train()\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for i, (images, labels) in enumerate(train_loader):\n",
    "                \n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                with autocast():\n",
    "                    outputs = self(images)\n",
    "                    labels = labels.unsqueeze(1).float()\n",
    "                    loss = self.criterion(outputs, labels)\n",
    "                scaler.scale(loss).backward()\n",
    "                # Gradient clipping\n",
    "                max_norm = 1.0  # Set the maximum allowable norm for the gradients\n",
    "                torch.nn.utils.clip_grad_norm_(self.parameters(), max_norm)\n",
    "                scaler.step(self.optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                if i%1000 == 0 and self.DEBUG:\n",
    "                    print(\" Step [{}/{}] Loss: {}\".format(i, len(train_loader), loss.item()))\n",
    "                    \n",
    "            val_acc, val_precision, val_recall, val_pauc, _ , _ = self.eval_val(val_loader)\n",
    "            train_acc, _, _, train_pauc, _, _ = self.eval_val(train_loader)\n",
    "\n",
    "            self.model_loss_history.append(running_loss/len(train_loader))\n",
    "            self.model_train_acc_history.append(train_acc.item())\n",
    "            self.model_train_pauc_history.append(train_pauc)\n",
    "            self.model_val_acc_history.append(val_acc.item())\n",
    "            self.model_val_precision_history.append(val_precision.item())\n",
    "            self.model_val_recall_history.append(val_recall.item())\n",
    "            self.model_val_pauc_history.append(val_pauc)\n",
    "            self.model_lr_history.append(self.optimizer.param_groups[0]['lr'])\n",
    "            \n",
    "            print(f'Epoch: {epoch+1}/{self.num_epochs}, Loss: {loss.item()},Train Acc: {train_acc}, Val Acc: {val_acc}, Val Precision: {val_precision}, Val Recall: {val_recall},Train PAUC: {train_pauc}, Val PAUC: {val_pauc}')\n",
    "            \n",
    "            if val_acc > last_accuracy:\n",
    "                last_accuracy = val_acc\n",
    "            elif self.early_stopping:\n",
    "                break\n",
    "        \n",
    "        print('Finished Training')\n",
    "\n",
    "    def plot_history(self):\n",
    "        # making two plots one for loss and other for accuracy\n",
    "        fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "        fig.suptitle('Model Training History')\n",
    "        axs[0, 0].plot(self.model_loss_history)\n",
    "        axs[0, 0].set_title('Model Loss')\n",
    "        axs[0, 0].set_xlabel('Epochs')\n",
    "        axs[0, 0].set_ylabel('Loss')\n",
    "\n",
    "        axs[0, 1].plot(self.model_train_acc_history, label='Train')\n",
    "        axs[0, 1].plot(self.model_val_acc_history, label='Val')\n",
    "        axs[0, 1].set_title('Model Accuracy')\n",
    "        axs[0, 1].set_xlabel('Epochs')\n",
    "        axs[0, 1].set_ylabel('Accuracy')\n",
    "        axs[0, 1].legend()\n",
    "\n",
    "        axs[1, 0].plot(self.model_val_precision_history)\n",
    "        axs[1, 0].set_title('Model Precision')\n",
    "        axs[1, 0].set_xlabel('Epochs')\n",
    "        axs[1, 0].set_ylabel('Precision')\n",
    "        \n",
    "        axs[1, 1].plot(self.model_val_recall_history)\n",
    "        axs[1, 1].set_title('Model Recall')\n",
    "        axs[1, 1].set_xlabel('Epochs')\n",
    "        axs[1, 1].set_ylabel('Recall')\n",
    "\n",
    "        axs[0, 2].plot(self.model_lr_history)\n",
    "        axs[0, 2].set_title('Learning Rate')\n",
    "        axs[0, 2].set_xlabel('Epochs')\n",
    "        axs[0, 2].set_ylabel('Learning Rate')\n",
    "        \n",
    "        axs[1, 2].plot(self.model_val_pauc_history)\n",
    "        axs[1, 2].set_title('Model Partial AUC')\n",
    "        axs[1, 2].set_xlabel('Epochs')\n",
    "        axs[1, 2].set_ylabel('Partial AUC')\n",
    "        \n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def save_model(self):\n",
    "        torch.save(self.state_dict(),type(self).__name__+'.pth')\n",
    "\n",
    "    def print_summary(self):\n",
    "        pass\n",
    "#         summary(self, (3, self.dim, self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfc4b6ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T05:49:38.994021Z",
     "iopub.status.busy": "2024-08-05T05:49:38.993788Z",
     "iopub.status.idle": "2024-08-05T05:49:39.932557Z",
     "shell.execute_reply": "2024-08-05T05:49:39.931697Z"
    },
    "papermill": {
     "duration": 0.949523,
     "end_time": "2024-08-05T05:49:39.934781",
     "exception": false,
     "start_time": "2024-08-05T05:49:38.985258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (criterion): BCEWithLogitsLoss()\n",
       "  (accuracy): BinaryAccuracy()\n",
       "  (precision): BinaryPrecision()\n",
       "  (recall): BinaryRecall()\n",
       "  (feature_extractor): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=1000, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=50, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = Model(num_classes=2, \n",
    "            device=device, \n",
    "            dim=dim, \n",
    "            num_epochs=2, \n",
    "            learning_rate=0.01,\n",
    "            early_stopping=False)\n",
    "cnn.to(device)\n",
    "# cnn.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08d4f492",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T05:49:39.952626Z",
     "iopub.status.busy": "2024-08-05T05:49:39.952344Z",
     "iopub.status.idle": "2024-08-05T05:49:39.956289Z",
     "shell.execute_reply": "2024-08-05T05:49:39.955453Z"
    },
    "papermill": {
     "duration": 0.01503,
     "end_time": "2024-08-05T05:49:39.958140",
     "exception": false,
     "start_time": "2024-08-05T05:49:39.943110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn.num_epochs = 5\n",
    "cnn.learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f19b4d73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T05:49:39.975465Z",
     "iopub.status.busy": "2024-08-05T05:49:39.974987Z",
     "iopub.status.idle": "2024-08-05T06:59:04.148212Z",
     "shell.execute_reply": "2024-08-05T06:59:04.147050Z"
    },
    "papermill": {
     "duration": 4164.193654,
     "end_time": "2024-08-05T06:59:04.159797",
     "exception": false,
     "start_time": "2024-08-05T05:49:39.966143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step [0/497] Loss: 0.7131290435791016\n",
      "Epoch: 1/5, Loss: 0.0010769193759188056,Train Acc: 0.9900990128517151, Val Acc: 0.9900491237640381, Val Precision: 0.0, Val Recall: 0.0,Train PAUC: 0.020761748188846216, Val PAUC: 0.009678873965278443\n",
      " Step [0/497] Loss: 0.0025984973181039095\n",
      "Epoch: 2/5, Loss: 2.50339240892572e-07,Train Acc: 0.9900990128517151, Val Acc: 0.9900906682014465, Val Precision: 0.0, Val Recall: 0.0,Train PAUC: 0.020315060539303584, Val PAUC: 0.0221119592875318\n",
      " Step [0/497] Loss: 0.00015256012557074428\n",
      "Epoch: 3/5, Loss: 0.0,Train Acc: 0.9900990128517151, Val Acc: 0.9900944828987122, Val Precision: 0.0, Val Recall: 0.0,Train PAUC: 0.017020498242637322, Val PAUC: 0.01453637316899467\n",
      " Step [0/497] Loss: 5.9604616353681195e-08\n",
      "Epoch: 4/5, Loss: 0.00021652717259712517,Train Acc: 0.9900990128517151, Val Acc: 0.9900959134101868, Val Precision: 0.0, Val Recall: 0.0,Train PAUC: 0.018921814145505526, Val PAUC: 0.018261088659382325\n",
      " Step [0/497] Loss: 4.472462023841217e-05\n",
      "Epoch: 5/5, Loss: 1.4305109630186053e-07,Train Acc: 0.9900990128517151, Val Acc: 0.9900966286659241, Val Precision: 0.0, Val Recall: 0.0,Train PAUC: 0.01902970570510244, Val PAUC: 0.018051399491094137\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "cnn.train_model(train_loader=train_loader,val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a4dbdde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T06:59:04.179827Z",
     "iopub.status.busy": "2024-08-05T06:59:04.179501Z",
     "iopub.status.idle": "2024-08-05T07:00:34.706849Z",
     "shell.execute_reply": "2024-08-05T07:00:34.705748Z"
    },
    "papermill": {
     "duration": 90.54998,
     "end_time": "2024-08-05T07:00:34.718865",
     "exception": false,
     "start_time": "2024-08-05T06:59:04.168885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pAUC: 0.019828173593440763, Precision: 0.0, Recall: 0.0\n"
     ]
    }
   ],
   "source": [
    "cnn_acc , cnn_precision, cnn_recall , cnn_pauc, y_pred, y_actual = cnn.eval_val(val_loader)\n",
    "print(f\"pAUC: {cnn_pauc}, Precision: {cnn_precision}, Recall: {cnn_recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "493d30c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T07:00:34.738704Z",
     "iopub.status.busy": "2024-08-05T07:00:34.738374Z",
     "iopub.status.idle": "2024-08-05T07:00:34.749062Z",
     "shell.execute_reply": "2024-08-05T07:00:34.748026Z"
    },
    "papermill": {
     "duration": 0.023618,
     "end_time": "2024-08-05T07:00:34.751580",
     "exception": false,
     "start_time": "2024-08-05T07:00:34.727962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7939, 0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.5 threshold\n",
    "y_pred = np.array(y_pred)\n",
    "y_actual = np.array(y_actual).astype(int)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# output the incorrect predictions\n",
    "incorrect_predictions = np.where(y_pred != y_actual)[0]\n",
    "number_zero = np.sum(y_pred == 0)\n",
    "number_one = np.sum(y_pred == 1)\n",
    "number_zero, number_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4729b8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T07:00:34.771597Z",
     "iopub.status.busy": "2024-08-05T07:00:34.771258Z",
     "iopub.status.idle": "2024-08-05T07:00:34.856153Z",
     "shell.execute_reply": "2024-08-05T07:00:34.855380Z"
    },
    "papermill": {
     "duration": 0.097403,
     "end_time": "2024-08-05T07:00:34.858496",
     "exception": false,
     "start_time": "2024-08-05T07:00:34.761093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d41455fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T07:00:34.878802Z",
     "iopub.status.busy": "2024-08-05T07:00:34.878510Z",
     "iopub.status.idle": "2024-08-05T07:00:35.063464Z",
     "shell.execute_reply": "2024-08-05T07:00:35.062346Z"
    },
    "papermill": {
     "duration": 0.197809,
     "end_time": "2024-08-05T07:00:35.065762",
     "exception": false,
     "start_time": "2024-08-05T07:00:34.867953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.19176775e-08, 1.19122676e-08, 1.19087691e-08], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prod_pred = []\n",
    "for images in test_loader:\n",
    "    images = images.to(device)\n",
    "    prob_outputs = cnn.predict(images)\n",
    "    y_prod_pred.extend(prob_outputs.cpu().numpy())\n",
    "\n",
    "y_prod_pred = np.array(y_prod_pred)\n",
    "y_prod_pred = y_prod_pred.flatten()\n",
    "y_prod_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9388bd06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T07:00:35.086933Z",
     "iopub.status.busy": "2024-08-05T07:00:35.086618Z",
     "iopub.status.idle": "2024-08-05T07:00:35.102944Z",
     "shell.execute_reply": "2024-08-05T07:00:35.102092Z"
    },
    "papermill": {
     "duration": 0.028858,
     "end_time": "2024-08-05T07:00:35.104793",
     "exception": false,
     "start_time": "2024-08-05T07:00:35.075935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0015657</td>\n",
       "      <td>1.191768e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015729</td>\n",
       "      <td>1.191227e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0015740</td>\n",
       "      <td>1.190877e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        isic_id        target\n",
       "0  ISIC_0015657  1.191768e-08\n",
       "1  ISIC_0015729  1.191227e-08\n",
       "2  ISIC_0015740  1.190877e-08"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = pd.DataFrame({'isic_id': test_metadata_df['isic_id'], 'target': y_prod_pred})\n",
    "submission_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "429181b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T07:00:35.125355Z",
     "iopub.status.busy": "2024-08-05T07:00:35.125058Z",
     "iopub.status.idle": "2024-08-05T07:00:35.133064Z",
     "shell.execute_reply": "2024-08-05T07:00:35.132392Z"
    },
    "papermill": {
     "duration": 0.02042,
     "end_time": "2024-08-05T07:00:35.134937",
     "exception": false,
     "start_time": "2024-08-05T07:00:35.114517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f6e629",
   "metadata": {
    "papermill": {
     "duration": 0.009766,
     "end_time": "2024-08-05T07:00:35.154352",
     "exception": false,
     "start_time": "2024-08-05T07:00:35.144586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9094797,
     "sourceId": 63056,
     "sourceType": "competition"
    },
    {
     "datasetId": 6885,
     "sourceId": 9959,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4280.451139,
   "end_time": "2024-08-05T07:00:38.132297",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-05T05:49:17.681158",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
