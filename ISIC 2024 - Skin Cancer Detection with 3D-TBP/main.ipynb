{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:55:40.143614Z","iopub.status.idle":"2024-07-17T09:55:53.617524Z","shell.execute_reply.started":"2024-07-17T09:55:40.144251Z","shell.execute_reply":"2024-07-17T09:55:53.616423Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Collecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\nDownloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport os\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.torch_version\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchsummary import summary\nfrom torchvision import transforms\nfrom torchmetrics import Accuracy, Precision, Recall\n\nimport cv2\nfrom joblib import Parallel, delayed\n\nfrom torch.cuda.amp import GradScaler, autocast\n","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:55:53.619932Z","iopub.execute_input":"2024-07-17T09:55:53.620758Z","iopub.status.idle":"2024-07-17T09:56:01.077690Z","shell.execute_reply.started":"2024-07-17T09:55:53.620719Z","shell.execute_reply":"2024-07-17T09:56:01.076908Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"device = (\n    \"cuda\"\n    if torch.cuda.is_available()\n    else \"mps\"\n    if torch.backends.mps.is_available()\n    else \"cpu\"\n)\nprint(f\"Using {device} device\")","metadata":{"execution":{"iopub.status.busy":"2024-07-17T09:56:01.078869Z","iopub.execute_input":"2024-07-17T09:56:01.079403Z","iopub.status.idle":"2024-07-17T09:56:01.117478Z","shell.execute_reply.started":"2024-07-17T09:56:01.079368Z","shell.execute_reply":"2024-07-17T09:56:01.116482Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Using cuda device\n","output_type":"stream"}]},{"cell_type":"code","source":"iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\nmain_path = '/kaggle/input/isic-2024-challenge' if iskaggle else 'data/isic-2024-challenge'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_metadata_path = '/kaggle/input/isic-2024-challenge/train-metadata.csv' if iskaggle else 'data/isic-2024-challenge/train-metadata.csv'\ntest_metadata_path = '/kaggle/input/isic-2024-challenge/test-metadata.csv' if iskaggle else 'data/isic-2024-challenge/test-metadata.csv'\n\ntrain_metadata_df = pd.read_csv(train_metadata_path)\ntest_metadata_df = pd.read_csv(test_metadata_path)\n\nprint(len(train_metadata_df))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn.model_selection as train_test_split\n\ntrain_size = 0.8\n# Splitting the train dataset into positive and negative samples and saving them in separate dataframes\npostive_samples = train_metadata_df[train_metadata_df['target'] == 1]\nnegative_samples = train_metadata_df[train_metadata_df['target'] == 0]\n\n# TODO: Taking Sample of 1% of the data\npostive_samples = postive_samples.sample(frac=0.01)\nnegative_samples = negative_samples.sample(frac=0.01)\n\nprint(f\"Positive samples: {postive_samples.shape}\")\nprint(f\"Negative samples: {negative_samples.shape}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Splitting each type of samples into train and validation sets\ntrain_positive_samples, val_positive_samples = train_test_split.train_test_split(postive_samples,test_size=1-train_size)\ntrain_negative_samples, val_negative_samples = train_test_split.train_test_split(negative_samples,test_size=1-train_size)\nprint(f\"Train positive samples: {train_positive_samples.shape}\")\nprint(f\"Train negative samples: {train_negative_samples.shape}\")\nprint(f\"Val positive samples: {val_positive_samples.shape}\")\nprint(f\"Val negative samples: {val_negative_samples.shape}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Concatenating the positive and negative samples to get the train and validation sets\ntrain_metadata_df = pd.concat([train_positive_samples, train_negative_samples])\nval_metadata_df = pd.concat([val_positive_samples, val_negative_samples])\nprint(f\"Train samples: {train_metadata_df.shape}\")\nprint(f\"Val samples: {val_metadata_df.shape}\")\nprint(f\"Test samples: {test_metadata_df.shape}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import h5py\nfrom io import BytesIO\n\ntrain_hdf5_path = '/kaggle/input/isic-2024-challenge/train-image.hdf5' if iskaggle else 'data/isic-2024-challenge/train-image.hdf5'\ntest_hdf5_path = '/kaggle/input/isic-2024-challenge/test-image.hdf5' if iskaggle else 'data/isic-2024-challenge/test-image.hdf5'\ntrain_image_path = '/kaggle/input/isic-2024-challenge/train-image/image' if iskaggle else 'data/isic-2024-challenge/train-image/image'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, hdf5_file_path, metadata_df,target=None, transform=None):\n        self.hdf5_file = h5py.File(self.hdf5_file_path, 'r')\n        self.hdf5_file_path = hdf5_file_path\n        self.metadata_df = metadata_df\n        self.image_ids = metadata_df['isic_id']\n        self.labels = target\n        self.transform = transform\n\n        self.mean_of_color_channels = None  # Initialize as None\n        self.std_of_color_channels = None   # Initialize as None\n        # self._calculate_stats()\n\n    def __len__(self):\n        return len(self.image_ids)\n\n    def __getitem__(self, idx):\n        image_id = self.image_ids.iloc[idx]\n        image = np.array(Image.open(BytesIO(self.hdf5_file[image_id][()])),dtype=np.float32)/255\n        \n        if self.transform:\n            image = self.transform(image=image)\n            image = image['image']\n\n        if self.labels is not None:\n            label = self.labels.iloc[idx]\n            return image, label\n        else:\n            return image\n\n   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# HyperParameters\ndim = 50 \nbatch_size = 128","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transform = A.Compose([\n    A.Resize(height=dim, width=dim), #resize \n    A.OneOf([A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15),\n             A.RandomBrightnessContrast() \n             ], p=0.5),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    # !!One needs to change the mean and std values to appropriate ones for this dataset.!!\n    A.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=1.0),\n    ToTensorV2(),\n])\n\n\ntest_transform = A.Compose([\n    A.Resize(height=dim, width=dim), #resize \n    # !!One needs to change the mean and std values to appropriate ones for this dataset.!!\n    A.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=1.0),\n    ToTensorV2(),\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = CustomDataset(train_hdf5_path,train_metadata_df,target=train_metadata_df['target'],transform=train_transform)\n# train_image_dataset = CustomDatasetImage(train_image_path,train_metadata_df,target=train_metadata_df['target'],transform=train_transform)\nval_dataset = CustomDataset(train_hdf5_path,val_metadata_df,target=val_metadata_df['target'],transform=train_transform)\ntest_dataset = CustomDataset(test_hdf5_path,test_metadata_df,transform=test_transform)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True,num_workers=4)\nval_loader = DataLoader(val_dataset,batch_size=batch_size,shuffle=True,num_workers=4)\ntest_loader = DataLoader(test_dataset,batch_size=batch_size,shuffle=False,num_workers=4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\n\ndef calculate_partial_auc_by_tpr(y_true, y_scores, max_tpr=0.8):\n    # Calculate the ROC curve\n    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n    \n    # Limit the TPR to the specified maximum\n    mask = tpr <= max_tpr\n    fpr, tpr = fpr[mask], tpr[mask]\n    \n    # Calculate the partial AUC\n    partial_auc = auc(fpr, tpr)\n    \n    # Normalize the partial AUC to the range [0, 1]\n    partial_auc /= max_tpr\n    \n    return partial_auc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self,num_classes,device,dim = 32,num_epochs = 20,learning_rate = 0.001,early_stopping = False):\n        super().__init__()\n        self.num_of_classes = num_classes\n        self.device = device\n        self.dim = dim\n        # Debugging\n        self.DEBUG = True\n        # Hyperparameters\n        self.num_epochs = num_epochs\n        self.learning_rate = learning_rate\n        self.early_stopping = early_stopping\n        # History while Training\n        self.model_loss_history = []\n        self.model_train_acc_history = []\n        self.model_val_acc_history = []\n        self.model_val_precision_history = []\n        self.model_val_recall_history = []\n        self.model_val_pauc_history = []\n        self.model_lr_history = []\n\n        # Model Attributes\n        self.criterion = nn.BCEWithLogitsLoss()\n        self.optimizer = None\n        self.accuracy = Accuracy(task= 'binary', average='macro').to(self.device)\n        self.precision = Precision(task= 'binary', average='macro').to(self.device)\n        self.recall = Recall(task= 'binary', average='macro').to(self.device)\n        # Feature Extraction\n        self.feature_extract = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            nn.Flatten()\n        )\n        \n        # Classifier\n        self.classifier = nn.Sequential(\n            nn.Linear(4608, 512),  # Adjust the size based on the input image size\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(512, 1),\n        )\n        \n    def forward(self, x):\n        x = self.feature_extract(x)\n        x = self.classifier(x)\n        return x\n    \n    def predict(self, img):\n        '''\n        returns the predicted classes for the given images\n        '''\n        self.eval()\n        with torch.no_grad():\n            img = img.to(self.device)\n            output = self(img)\n            _, predicted = torch.max(output, 1)\n            return predicted\n        \n\n    \n    def eval_val(self, data_loader):\n        '''\n        returns accuracy, precision and recall\n        '''\n        self.eval()\n        y_pred = []\n        y_actual = []\n        with torch.no_grad():\n            for images, labels in data_loader:\n                \n                images, labels = images.to(self.device), labels.to(self.device)\n                outputs = self(images)\n                labels = labels.unsqueeze(1).float()\n                self.accuracy(outputs, labels)\n                self.precision(outputs, labels)\n                self.recall(outputs, labels)\n\n                y_pred.extend(outputs.cpu().numpy())\n                y_actual.extend(labels.cpu().numpy())\n        \n        partial_auc = calculate_partial_auc_by_tpr(y_actual, y_pred)\n\n\n        return self.accuracy.compute(), self.precision.compute(), self.recall.compute(), partial_auc, y_pred, y_actual\n    \n    def train_model(self, train_loader, val_loader):\n        \n        last_accuracy = -100\n        self.optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n        scaler = GradScaler()\n\n        for epoch in range(self.num_epochs):\n            self.train()\n            running_loss = 0.0\n\n            for i, (images, labels) in enumerate(train_loader):\n                \n                images, labels = images.to(self.device), labels.to(self.device)\n                self.optimizer.zero_grad()\n                with autocast():\n                    outputs = self(images)\n                    labels = labels.unsqueeze(1).float()\n                    loss = self.criterion(outputs, labels)\n                scaler.scale(loss).backward()\n                scaler.step(self.optimizer)\n                scaler.update()\n\n                running_loss += loss.item()\n                if i%1000 == 0 and self.DEBUG:\n                    print(\" Step [{}/{}] Loss: {}\".format(i, len(train_loader), loss.item()))\n                    \n            val_acc, val_precision, val_recall, val_pauc, _ , _ = self.eval_val(val_loader)\n            train_acc, _, _, _, _, _ = self.eval_val(train_loader)\n\n            self.model_loss_history.append(running_loss/len(train_loader))\n            self.model_train_acc_history.append(train_acc.item())\n            self.model_val_acc_history.append(val_acc.item())\n            self.model_val_precision_history.append(val_precision.item())\n            self.model_val_recall_history.append(val_recall.item())\n            self.model_val_pauc_history.append(val_pauc)\n            self.model_lr_history.append(self.optimizer.param_groups[0]['lr'])\n            \n            print(f'Epoch: {epoch+1}/{self.num_epochs}, Loss: {loss.item()},Train Acc: {train_acc}, Val Acc: {val_acc}, Val Precision: {val_precision}, Val Recall: {val_recall}, Val PAUC: {val_pauc}')\n            \n            if val_acc > last_accuracy:\n                last_accuracy = val_acc\n            elif self.early_stopping:\n                break\n        \n        print('Finished Training')\n\n    def plot_history(self):\n        # making two plots one for loss and other for accuracy\n        fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n        fig.suptitle('Model Training History')\n        axs[0, 0].plot(self.model_loss_history)\n        axs[0, 0].set_title('Model Loss')\n        axs[0, 0].set_xlabel('Epochs')\n        axs[0, 0].set_ylabel('Loss')\n\n        axs[0, 1].plot(self.model_train_acc_history, label='Train')\n        axs[0, 1].plot(self.model_val_acc_history, label='Val')\n        axs[0, 1].set_title('Model Accuracy')\n        axs[0, 1].set_xlabel('Epochs')\n        axs[0, 1].set_ylabel('Accuracy')\n        axs[0, 1].legend()\n\n        axs[1, 0].plot(self.model_val_precision_history)\n        axs[1, 0].set_title('Model Precision')\n        axs[1, 0].set_xlabel('Epochs')\n        axs[1, 0].set_ylabel('Precision')\n        \n        axs[1, 1].plot(self.model_val_recall_history)\n        axs[1, 1].set_title('Model Recall')\n        axs[1, 1].set_xlabel('Epochs')\n        axs[1, 1].set_ylabel('Recall')\n\n        axs[0, 2].plot(self.model_lr_history)\n        axs[0, 2].set_title('Learning Rate')\n        axs[0, 2].set_xlabel('Epochs')\n        axs[0, 2].set_ylabel('Learning Rate')\n        \n        axs[1, 2].plot(self.model_val_pauc_history)\n        axs[1, 2].set_title('Model Partial AUC')\n        axs[1, 2].set_xlabel('Epochs')\n        axs[1, 2].set_ylabel('Partial AUC')\n        \n\n        plt.show()\n    \n    def save_model(self):\n        torch.save(self.state_dict(),type(self).__name__+'.pth')\n\n    def print_summary(self):\n        summary(self, (3, self.dim, self.dim))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_of_classes = 2\ncnn = Model(num_classes=num_of_classes, \n            device=device, \n            dim=dim, \n            num_epochs=2, \n            learning_rate=0.001,\n            early_stopping=False)\ncnn.to(device)\ncnn.print_summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn.train_model(train_loader=train_loader,val_loader=val_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_acc , cnn_precision, cnn_recall , cnn_pauc, y_pred, y_actual = cnn.eval_val(val_loader)\nprint(f\"Accuracy: {cnn_pauc}, Precision: {cnn_precision}, Recall: {cnn_recall}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Partial AUC: {cnn_pauc}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn.plot_history()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}