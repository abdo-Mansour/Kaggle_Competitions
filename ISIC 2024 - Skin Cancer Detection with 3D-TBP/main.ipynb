{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-07-14T14:58:59.640628Z","iopub.execute_input":"2024-07-14T14:58:59.640921Z","iopub.status.idle":"2024-07-14T14:59:13.467881Z","shell.execute_reply.started":"2024-07-14T14:58:59.640896Z","shell.execute_reply":"2024-07-14T14:59:13.466787Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\nDownloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport os\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.torch_version\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchsummary import summary\nfrom torchvision import transforms\nfrom torchmetrics import Accuracy, Precision, Recall","metadata":{"execution":{"iopub.status.busy":"2024-07-14T14:59:13.469675Z","iopub.execute_input":"2024-07-14T14:59:13.469986Z","iopub.status.idle":"2024-07-14T14:59:21.602022Z","shell.execute_reply.started":"2024-07-14T14:59:13.469955Z","shell.execute_reply":"2024-07-14T14:59:21.601039Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"device = (\n    \"cuda\"\n    if torch.cuda.is_available()\n    else \"mps\"\n    if torch.backends.mps.is_available()\n    else \"cpu\"\n)\nprint(f\"Using {device} device\")","metadata":{"execution":{"iopub.status.busy":"2024-07-14T14:59:21.603264Z","iopub.execute_input":"2024-07-14T14:59:21.603817Z","iopub.status.idle":"2024-07-14T14:59:21.646221Z","shell.execute_reply.started":"2024-07-14T14:59:21.603784Z","shell.execute_reply":"2024-07-14T14:59:21.645441Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Using cuda device\n","output_type":"stream"}]},{"cell_type":"code","source":"iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\nmain_path = '/kaggle/input/isic-2024-challenge' if iskaggle else 'data/isic-2024-challenge'","metadata":{"execution":{"iopub.status.busy":"2024-07-14T14:59:21.648118Z","iopub.execute_input":"2024-07-14T14:59:21.648439Z","iopub.status.idle":"2024-07-14T14:59:21.655788Z","shell.execute_reply.started":"2024-07-14T14:59:21.648407Z","shell.execute_reply":"2024-07-14T14:59:21.654823Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_metadata_path = '/kaggle/input/isic-2024-challenge/train-metadata.csv' if iskaggle else 'data/isic-2024-challenge/train-metadata.csv'\ntest_metadata_path = '/kaggle/input/isic-2024-challenge/test-metadata.csv' if iskaggle else 'data/isic-2024-challenge/test-metadata.csv'\n\ntrain_metadata_df = pd.read_csv(train_metadata_path)\ntest_metadata_df = pd.read_csv(test_metadata_path)\n\nprint(len(train_metadata_df))","metadata":{"execution":{"iopub.status.busy":"2024-07-14T14:59:21.656904Z","iopub.execute_input":"2024-07-14T14:59:21.657462Z","iopub.status.idle":"2024-07-14T14:59:28.478130Z","shell.execute_reply.started":"2024-07-14T14:59:21.657431Z","shell.execute_reply":"2024-07-14T14:59:28.477285Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/3275392473.py:4: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n  train_metadata_df = pd.read_csv(train_metadata_path)\n","output_type":"stream"},{"name":"stdout","text":"401059\n","output_type":"stream"}]},{"cell_type":"code","source":"import sklearn.model_selection as train_test_split\n\ntrain_size = 0.8\n# Splitting the train dataset into positive and negative samples and saving them in separate dataframes\npostive_samples = train_metadata_df[train_metadata_df['target'] == 1]\nnegative_samples = train_metadata_df[train_metadata_df['target'] == 0]\nprint(f\"Positive samples: {postive_samples.shape}\")\nprint(f\"Negative samples: {negative_samples.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-14T14:59:28.479176Z","iopub.execute_input":"2024-07-14T14:59:28.479480Z","iopub.status.idle":"2024-07-14T14:59:28.595104Z","shell.execute_reply.started":"2024-07-14T14:59:28.479456Z","shell.execute_reply":"2024-07-14T14:59:28.594208Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Positive samples: (393, 55)\nNegative samples: (400666, 55)\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Splitting each type of samples into train and validation sets\ntrain_positive_samples, val_positive_samples = train_test_split.train_test_split(postive_samples,test_size=1-train_size)\ntrain_negative_samples, val_negative_samples = train_test_split.train_test_split(negative_samples,test_size=1-train_size)\nprint(f\"Train positive samples: {train_positive_samples.shape}\")\nprint(f\"Train negative samples: {train_negative_samples.shape}\")\nprint(f\"Val positive samples: {val_positive_samples.shape}\")\nprint(f\"Val negative samples: {val_negative_samples.shape}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-14T15:00:19.439686Z","iopub.execute_input":"2024-07-14T15:00:19.440041Z","iopub.status.idle":"2024-07-14T15:00:19.957290Z","shell.execute_reply.started":"2024-07-14T15:00:19.440011Z","shell.execute_reply":"2024-07-14T15:00:19.956162Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Train positive samples: (314, 55)\nTrain negative samples: (320532, 55)\nVal positive samples: (79, 55)\nVal negative samples: (80134, 55)\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Concatenating the positive and negative samples to get the train and validation sets\ntrain_metadata_df = pd.concat([train_positive_samples, train_negative_samples])\nval_metadata_df = pd.concat([val_positive_samples, val_negative_samples])\nprint(f\"Train samples: {train_metadata_df.shape}\")\nprint(f\"Val samples: {val_metadata_df.shape}\")\nprint(f\"Test samples: {test_metadata_df.shape}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-14T15:00:21.398864Z","iopub.execute_input":"2024-07-14T15:00:21.399544Z","iopub.status.idle":"2024-07-14T15:00:21.581306Z","shell.execute_reply.started":"2024-07-14T15:00:21.399512Z","shell.execute_reply":"2024-07-14T15:00:21.580400Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Train samples: (320846, 55)\nVal samples: (80213, 55)\nTest samples: (3, 44)\n","output_type":"stream"}]},{"cell_type":"code","source":"import h5py\nfrom io import BytesIO\n\ntrain_hdf5_path = '/kaggle/input/isic-2024-challenge/train-image.hdf5' if iskaggle else 'data/isic-2024-challenge/train-image.hdf5'\ntest_hdf5_path = '/kaggle/input/isic-2024-challenge/test-image.hdf5' if iskaggle else 'data/isic-2024-challenge/test-image.hdf5'\ntrain_image_path = '/kaggle/input/isic-2024-challenge/train-image/image' if iskaggle else 'data/isic-2024-challenge/train-image/image'","metadata":{"execution":{"iopub.status.busy":"2024-07-14T15:00:22.210639Z","iopub.execute_input":"2024-07-14T15:00:22.211250Z","iopub.status.idle":"2024-07-14T15:00:22.354835Z","shell.execute_reply.started":"2024-07-14T15:00:22.211219Z","shell.execute_reply":"2024-07-14T15:00:22.354100Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, hdf5_file_path, metadata_df,target=None, transform=None):\n        self.hdf5_file = h5py.File(hdf5_file_path,'r')\n        self.metadata_df = metadata_df\n        self.image_ids = metadata_df['isic_id']\n        self.labels = target\n        self.transform = transform\n\n        self.mean_of_color_channels = None  # Initialize as None\n        self.std_of_color_channels = None   # Initialize as None\n        # self._calculate_stats()\n\n    def __len__(self):\n        return len(self.image_ids)\n\n    def __getitem__(self, idx):\n        image_id = self.image_ids.iloc[idx]\n        image = np.array(Image.open(BytesIO(self.hdf5_file[image_id][()])),dtype=np.float32)/255\n        \n        # Calculate mean and standard deviation if not already done\n        # if self.mean_of_color_channels is None or self.std_of_color_channels is None:\n        #     self._calculate_stats()\n\n        # Apply transformation with calculated statistics\n        if self.transform:\n            image = self.transform(image=image)\n            image = image['image']\n\n        if self.labels is not None:\n            label = self.labels.iloc[idx]\n            return image, label\n        else:\n            return image\n   ","metadata":{"execution":{"iopub.status.busy":"2024-07-14T15:00:22.908778Z","iopub.execute_input":"2024-07-14T15:00:22.909598Z","iopub.status.idle":"2024-07-14T15:00:22.918298Z","shell.execute_reply.started":"2024-07-14T15:00:22.909567Z","shell.execute_reply":"2024-07-14T15:00:22.917265Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# HyperParameters\ndim = 50\nbatch_size = 64","metadata":{"execution":{"iopub.status.busy":"2024-07-14T15:00:30.574089Z","iopub.execute_input":"2024-07-14T15:00:30.574709Z","iopub.status.idle":"2024-07-14T15:00:30.579707Z","shell.execute_reply.started":"2024-07-14T15:00:30.574676Z","shell.execute_reply":"2024-07-14T15:00:30.578752Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_transform = A.Compose([\n    A.Resize(height=50, width=50), #resize \n    A.OneOf([A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15),\n             A.RandomBrightnessContrast() \n             ], p=0.5),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    # !!One needs to change the mean and std values to appropriate ones for this dataset.!!\n    A.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=1.0),\n    ToTensorV2(),\n])\n\n\ntest_transform = A.Compose([\n    A.Resize(height=50, width=50), #resize \n    # !!One needs to change the mean and std values to appropriate ones for this dataset.!!\n    A.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=1.0),\n    ToTensorV2(),\n])","metadata":{"execution":{"iopub.status.busy":"2024-07-14T15:00:31.387671Z","iopub.execute_input":"2024-07-14T15:00:31.388026Z","iopub.status.idle":"2024-07-14T15:00:31.396022Z","shell.execute_reply.started":"2024-07-14T15:00:31.387997Z","shell.execute_reply":"2024-07-14T15:00:31.395041Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_dataset = CustomDataset(train_hdf5_path,train_metadata_df,target=train_metadata_df['target'],transform=train_transform)\n# train_image_dataset = CustomDatasetImage(train_image_path,train_metadata_df,target=train_metadata_df['target'],transform=train_transform)\nval_dataset = CustomDataset(train_hdf5_path,val_metadata_df,target=val_metadata_df['target'],transform=train_transform)\ntest_dataset = CustomDataset(test_hdf5_path,test_metadata_df,transform=test_transform)","metadata":{"execution":{"iopub.status.busy":"2024-07-14T15:00:32.074601Z","iopub.execute_input":"2024-07-14T15:00:32.074945Z","iopub.status.idle":"2024-07-14T15:00:32.102336Z","shell.execute_reply.started":"2024-07-14T15:00:32.074917Z","shell.execute_reply":"2024-07-14T15:00:32.101508Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True,num_workers=4,pin_memory=True)\nval_loader = DataLoader(val_dataset,batch_size=batch_size,shuffle=True,num_workers=4,pin_memory=True)\ntest_loader = DataLoader(test_dataset,batch_size=batch_size,shuffle=False,num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2024-07-14T15:04:48.845336Z","iopub.execute_input":"2024-07-14T15:04:48.846150Z","iopub.status.idle":"2024-07-14T15:04:48.852142Z","shell.execute_reply.started":"2024-07-14T15:04:48.846114Z","shell.execute_reply":"2024-07-14T15:04:48.851245Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\n\ndef calculate_partial_auc_by_tpr(y_true, y_scores, max_tpr=0.8):\n    # Calculate the ROC curve\n    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n    \n    # Limit the TPR to the specified maximum\n    mask = tpr <= max_tpr\n    fpr, tpr = fpr[mask], tpr[mask]\n    \n    # Calculate the partial AUC\n    partial_auc = auc(fpr, tpr)\n    \n    # Normalize the partial AUC to the range [0, 1]\n    partial_auc /= max_tpr\n    \n    return partial_auc","metadata":{"execution":{"iopub.status.busy":"2024-07-14T15:04:50.139911Z","iopub.execute_input":"2024-07-14T15:04:50.140289Z","iopub.status.idle":"2024-07-14T15:04:50.146205Z","shell.execute_reply.started":"2024-07-14T15:04:50.140251Z","shell.execute_reply":"2024-07-14T15:04:50.145167Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self,num_classes,device,dim = 32,num_epochs = 20,learning_rate = 0.001,early_stopping = False):\n        super().__init__()\n        self.num_of_classes = num_classes\n        self.device = device\n        self.dim = dim\n        # Debugging\n        self.DEBUG = True\n        # Hyperparameters\n        self.num_epochs = num_epochs\n        self.learning_rate = learning_rate\n        self.early_stopping = early_stopping\n        # History while Training\n        self.model_loss_history = []\n        self.model_train_acc_history = []\n        self.model_val_acc_history = []\n        self.model_val_precision_history = []\n        self.model_val_recall_history = []\n        self.model_val_pauc_history = []\n        self.model_lr_history = []\n\n        # Model Attributes\n        self.criterion = nn.BCELoss()\n        self.optimizer = None\n        self.accuracy = Accuracy(task= 'binary', average='macro').to(self.device)\n        self.precision = Precision(task= 'binary', average='macro').to(self.device)\n        self.recall = Recall(task= 'binary', average='macro').to(self.device)\n        # Feature Extraction\n        self.feature_extract = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            nn.Flatten()\n        )\n        \n        # Classifier\n        self.classifier = nn.Sequential(\n            nn.Linear(4608, 512),  # Adjust the size based on the input image size\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(512, 1),\n            nn.Sigmoid()\n        )\n        \n    def forward(self, x):\n        x = self.feature_extract(x)\n        x = self.classifier(x)\n        return x\n    \n    def predict(self, img):\n        '''\n        returns the predicted classes for the given images\n        '''\n        self.eval()\n        with torch.no_grad():\n            img = img.to(self.device)\n            output = self(img)\n            _, predicted = torch.max(output, 1)\n            return predicted\n        \n\n    \n    def eval_val(self, data_loader):\n        '''\n        returns accuracy, precision and recall\n        '''\n        self.eval()\n        y_pred = []\n        y_actual = []\n        with torch.no_grad():\n            for images, labels in data_loader:\n                \n                images, labels = images.to(self.device), labels.to(self.device)\n                outputs = self(images)\n                labels = labels.unsqueeze(1).float()\n                self.accuracy(outputs, labels)\n                self.precision(outputs, labels)\n                self.recall(outputs, labels)\n\n                y_pred.extend(outputs.cpu().numpy())\n                y_actual.extend(labels.cpu().numpy())\n        \n        partial_auc = calculate_partial_auc_by_tpr(y_actual, y_pred)\n\n\n        return self.accuracy.compute(), self.precision.compute(), self.recall.compute(), partial_auc, y_pred, y_actual\n    \n    def train_model(self, train_loader, val_loader):\n        \n        last_accuracy = -100\n        self.optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n\n        for epoch in range(self.num_epochs):\n            self.train()\n            running_loss = 0.0\n\n            for i, (images, labels) in enumerate(train_loader):\n                \n                images, labels = images.to(self.device), labels.to(self.device)\n                self.optimizer.zero_grad()\n                outputs = self(images)\n                labels = labels.unsqueeze(1).float()\n                loss = self.criterion(outputs, labels)\n                loss.backward()\n                self.optimizer.step()\n\n                running_loss += loss.item()\n                if i%1000 == 0 and self.DEBUG:\n                    print(\" Step [{}/{}] Loss: {}\".format(i, len(train_loader), loss.item()))\n                    \n            val_acc, val_precision, val_recall, val_pauc, _ , _ = self.eval_val(val_loader)\n            train_acc, _, _, _, _, _ = self.eval_val(train_loader)\n\n            self.model_loss_history.append(running_loss/len(train_loader))\n            self.model_train_acc_history.append(train_acc.item())\n            self.model_val_acc_history.append(val_acc.item())\n            self.model_val_precision_history.append(val_precision.item())\n            self.model_val_recall_history.append(val_recall.item())\n            self.model_val_pauc_history.append(val_pauc)\n            self.model_lr_history.append(self.optimizer.param_groups[0]['lr'])\n            \n            print(f'Epoch: {epoch+1}/{self.num_epochs}, Loss: {loss.item()},Train Acc: {train_acc}, Val Acc: {val_acc}, Val Precision: {val_precision}, Val Recall: {val_recall}, Val PAUC: {val_pauc}')\n            \n            if val_acc > last_accuracy:\n                last_accuracy = val_acc\n            elif self.early_stopping:\n                break\n        \n        print('Finished Training')\n\n    def plot_history(self):\n        # making two plots one for loss and other for accuracy\n        fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n        fig.suptitle('Model Training History')\n        axs[0, 0].plot(self.model_loss_history)\n        axs[0, 0].set_title('Model Loss')\n        axs[0, 0].set_xlabel('Epochs')\n        axs[0, 0].set_ylabel('Loss')\n\n        axs[0, 1].plot(self.model_train_acc_history, label='Train')\n        axs[0, 1].plot(self.model_val_acc_history, label='Val')\n        axs[0, 1].set_title('Model Accuracy')\n        axs[0, 1].set_xlabel('Epochs')\n        axs[0, 1].set_ylabel('Accuracy')\n        axs[0, 1].legend()\n\n        axs[1, 0].plot(self.model_val_precision_history)\n        axs[1, 0].set_title('Model Precision')\n        axs[1, 0].set_xlabel('Epochs')\n        axs[1, 0].set_ylabel('Precision')\n        \n        axs[1, 1].plot(self.model_val_recall_history)\n        axs[1, 1].set_title('Model Recall')\n        axs[1, 1].set_xlabel('Epochs')\n        axs[1, 1].set_ylabel('Recall')\n\n        axs[0, 2].plot(self.model_lr_history)\n        axs[0, 2].set_title('Learning Rate')\n        axs[0, 2].set_xlabel('Epochs')\n        axs[0, 2].set_ylabel('Learning Rate')\n        \n        axs[1, 2].plot(self.model_val_pauc_history)\n        axs[1, 2].set_title('Model Partial AUC')\n        axs[1, 2].set_xlabel('Epochs')\n        axs[1, 2].set_ylabel('Partial AUC')\n        \n\n        plt.show()\n    \n    def save_model(self):\n        torch.save(self.state_dict(),type(self).__name__+'.pth')\n\n    def print_summary(self):\n        summary(self, (3, self.dim, self.dim))","metadata":{"execution":{"iopub.status.busy":"2024-07-14T15:04:50.524668Z","iopub.execute_input":"2024-07-14T15:04:50.525030Z","iopub.status.idle":"2024-07-14T15:04:50.559327Z","shell.execute_reply.started":"2024-07-14T15:04:50.524998Z","shell.execute_reply":"2024-07-14T15:04:50.558322Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"num_of_classes = 2\ncnn = Model(num_classes=num_of_classes, \n            device=device, \n            dim=dim, \n            num_epochs=2, \n            learning_rate=0.001,\n            early_stopping=False)\ncnn.to(device)\ncnn.print_summary()","metadata":{"execution":{"iopub.status.busy":"2024-07-14T15:04:50.916895Z","iopub.execute_input":"2024-07-14T15:04:50.917785Z","iopub.status.idle":"2024-07-14T15:04:50.958415Z","shell.execute_reply.started":"2024-07-14T15:04:50.917750Z","shell.execute_reply":"2024-07-14T15:04:50.957422Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 32, 50, 50]             896\n              ReLU-2           [-1, 32, 50, 50]               0\n         MaxPool2d-3           [-1, 32, 25, 25]               0\n            Conv2d-4           [-1, 64, 25, 25]          18,496\n              ReLU-5           [-1, 64, 25, 25]               0\n         MaxPool2d-6           [-1, 64, 12, 12]               0\n            Conv2d-7          [-1, 128, 12, 12]          73,856\n              ReLU-8          [-1, 128, 12, 12]               0\n         MaxPool2d-9            [-1, 128, 6, 6]               0\n          Flatten-10                 [-1, 4608]               0\n           Linear-11                  [-1, 512]       2,359,808\n             ReLU-12                  [-1, 512]               0\n          Dropout-13                  [-1, 512]               0\n           Linear-14                    [-1, 1]             513\n          Sigmoid-15                    [-1, 1]               0\n================================================================\nTotal params: 2,453,569\nTrainable params: 2,453,569\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.03\nForward/backward pass size (MB): 2.42\nParams size (MB): 9.36\nEstimated Total Size (MB): 11.81\n----------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"cnn.train_model(train_loader=train_loader,val_loader=val_loader)","metadata":{"execution":{"iopub.status.busy":"2024-07-14T15:04:52.010978Z","iopub.execute_input":"2024-07-14T15:04:52.011716Z","iopub.status.idle":"2024-07-14T15:08:21.002170Z","shell.execute_reply.started":"2024-07-14T15:04:52.011680Z","shell.execute_reply":"2024-07-14T15:08:21.000800Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":" Step [0/5014] Loss: 0.7037521600723267\n Step [1000/5014] Loss: 0.0\n Step [2000/5014] Loss: 0.0\n Step [3000/5014] Loss: 0.0\n Step [4000/5014] Loss: 0.0\n Step [5000/5014] Loss: 0.0\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[26], line 117\u001b[0m, in \u001b[0;36mModel.train_model\u001b[0;34m(self, train_loader, val_loader)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDEBUG:\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Step [\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m] Loss: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i, \u001b[38;5;28mlen\u001b[39m(train_loader), loss\u001b[38;5;241m.\u001b[39mitem()))\n\u001b[0;32m--> 117\u001b[0m val_acc, val_precision, val_recall, val_pauc, _ , _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_val\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m train_acc, _, _, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_val(train_loader)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_loss_history\u001b[38;5;241m.\u001b[39mappend(running_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader))\n","Cell \u001b[0;32mIn[26], line 89\u001b[0m, in \u001b[0;36mModel.eval_val\u001b[0;34m(self, data_loader)\u001b[0m\n\u001b[1;32m     86\u001b[0m         y_pred\u001b[38;5;241m.\u001b[39mextend(outputs\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     87\u001b[0m         y_actual\u001b[38;5;241m.\u001b[39mextend(labels\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m---> 89\u001b[0m partial_auc \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_partial_auc_by_tpr\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_actual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccuracy\u001b[38;5;241m.\u001b[39mcompute(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision\u001b[38;5;241m.\u001b[39mcompute(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecall\u001b[38;5;241m.\u001b[39mcompute(), partial_auc, y_pred, y_actual\n","Cell \u001b[0;32mIn[25], line 12\u001b[0m, in \u001b[0;36mcalculate_partial_auc_by_tpr\u001b[0;34m(y_true, y_scores, max_tpr)\u001b[0m\n\u001b[1;32m      9\u001b[0m fpr, tpr \u001b[38;5;241m=\u001b[39m fpr[mask], tpr[mask]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Calculate the partial AUC\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m partial_auc \u001b[38;5;241m=\u001b[39m \u001b[43mauc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtpr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Normalize the partial AUC to the range [0, 1]\u001b[39;00m\n\u001b[1;32m     15\u001b[0m partial_auc \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m max_tpr\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:90\u001b[0m, in \u001b[0;36mauc\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     87\u001b[0m y \u001b[38;5;241m=\u001b[39m column_or_1d(y)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m---> 90\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least 2 points are needed to compute area under curve, but x.shape = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;241m%\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     93\u001b[0m     )\n\u001b[1;32m     95\u001b[0m direction \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     96\u001b[0m dx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdiff(x)\n","\u001b[0;31mValueError\u001b[0m: At least 2 points are needed to compute area under curve, but x.shape = 1"],"ename":"ValueError","evalue":"At least 2 points are needed to compute area under curve, but x.shape = 1","output_type":"error"}]},{"cell_type":"code","source":"cnn_acc , cnn_precision, cnn_recall , cnn_pauc, y_pred, y_actual = cnn.eval_val(val_loader)\nprint(f\"Accuracy: {cnn_acc}, Precision: {cnn_precision}, Recall: {cnn_recall}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Partial AUC: {cnn_pauc}\")\nprint(y_pred, y_actual)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn.plot_history()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn.save_model()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}